# 综合实验六：奇异值分解（SVD）图像压缩

## 实验原理

奇异值分解（Singular Value Decomposition, SVD）是线性代数中一种重要的矩阵分解方法。对于任意实矩阵 $A \in \mathbb{R}^{m \times n}$，都可以分解为：

$$A = U\Sigma V^T$$

其中：
- $U \in \mathbb{R}^{m \times m}$ 是左奇异向量矩阵，满足 $U^TU = I$
- $\Sigma \in \mathbb{R}^{m \times n}$ 是对角矩阵，对角线上的元素 $\sigma_1 \geq \sigma_2 \geq \cdots \geq \sigma_r > 0$ 称为奇异值
- $V \in \mathbb{R}^{n \times n}$ 是右奇异向量矩阵，满足 $V^TV = I$

当使用前 $k$ 个最大的奇异值进行低秩近似时：

$$A_k = \sum_{i=1}^{k} \sigma_i u_i v_i^T$$

这样可以用较少的参数表示原矩阵，实现数据压缩。压缩率计算公式为：

$$\text{压缩率} = \frac{k(m + n + 1)}{mn}$$

其中 $k$ 是保留的奇异值个数，$m \times n$ 是原矩阵的尺寸。

## 实验步骤

1. **图像加载与预处理**：读取目标图像 `Noir_from_ZN.png`，并将其转换为灰度矩阵，像素值范围为 0-255。

2. **奇异值分解**：调用 `numpy.linalg.svd()` 函数对灰度图像矩阵执行 SVD 分解，得到左奇异向量矩阵 U、奇异值向量 S 和右奇异向量矩阵 V^T。

3. **选择重建秩**：根据图像尺寸自动选择若干个代表性的秩值（如 5, 20, 50, 100, 150, 200），用于展示不同压缩程度下的重建效果。

4. **图像重建**：对于每个选定的秩 k，使用前 k 个奇异值及其对应的奇异向量重建图像，计算公式为 $A_k = U[:, :k] \cdot \text{diag}(S[:k]) \cdot V^T[:k, :]$，并将像素值裁剪到 0-255 范围内。

5. **压缩率计算**：对每个秩 k，计算理论压缩率，即 SVD 表示所需的参数量与原图像参数量的比值。

6. **可视化展示**：生成两张图表：
   - 第一张展示原始图像与不同秩下的重建结果对比，标注相应的压缩率
   - 第二张绘制奇异值衰减曲线（对数坐标），直观展示奇异值的分布特征

7. **结果保存**：将生成的可视化图表以高分辨率（300 DPI）保存到实验目录中。

## 实验心得体会与思考

这次实验让我真实地感受到了 SVD 的威力。看到用很少的奇异值就能重建出差不多的图像，挺神奇的。特别是奇异值曲线图，能明显看出前面几个奇异值特别大，后面的就迅速衰减了，这就解释了为什么可以做压缩。不过我也发现，秩太小的话图像就很模糊，细节全丢了；秩太大压缩效果又不明显。所以实际应用中得权衡一下质量和存储空间。总的来说，这个实验让我对线性代数里学的理论有了更直观的认识，原来这些数学工具在图像处理、数据压缩这些领域真的能派上大用场！
